{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install dependencies\n",
        "# Use CUDA 11.8 PyTorch wheels (Colab typically supports these). If it fails, try the pip installs without the extra index.\n",
        "!pip install -U torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install decord==0.6.4 ffmpeg-python tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d_thHEplok4",
        "outputId": "8661d8db-91d0-430a-9fb8-0f6c5df8c77f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting torch\n",
            "  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.8.0 torchvision-0.23.0 triton-3.4.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement decord==0.6.4 (from versions: 0.0.1b20190911, 0.0.1b20190912, 0.0.1b20190913, 0.0.1b20190927, 0.2.0b20190927, 0.2.0b20190929, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 0.3.4, 0.3.5, 0.3.6, 0.3.7, 0.3.8, 0.3.9, 0.4.0, 0.4.1, 0.4.2, 0.5.0, 0.5.1, 0.5.2, 0.6.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for decord==0.6.4\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/Priyanka_Project/NORMAL.zip -d /content\n",
        "!unzip -q /content/drive/MyDrive/Priyanka_Project/cashlifting.zip -d /content"
      ],
      "metadata": {
        "id": "uvX9if4rlsEn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update these to your paths (you said the data is already at these locations)\n",
        "NORMAL_DIR = \"/content/NORAML \"          # -> contains 2 x 1hr normal videos (.mp4/.avi/.dav converted to mp4)\n",
        "CASHLIFT_DIR = \"/content/cashlifting\"  # -> contains 5 clips (mp4)\n",
        "OUTPUT_CLIPS_DIR = \"/content/clip_dataset\"   # where labeled clips will be saved\n",
        "MODEL_DIR = \"/content/drive/MyDrive/cashlift_model\"  # save trained model to Drive\n",
        "\n",
        "\n",
        "import os\n",
        "os.makedirs(OUTPUT_CLIPS_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "print(\"Paths set. NORMAL_DIR:\", NORMAL_DIR, \"CASHLIFT_DIR:\", CASHLIFT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ODxSPcTlpGk",
        "outputId": "3e5c0901-883d-4893-9ae4-03e9f016e5bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paths set. NORMAL_DIR: /content/NORAML  CASHLIFT_DIR: /content/cashlifting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, subprocess, glob\n",
        "folders = [\"/content/NORMAL\", \"/content/cashlifting\"]\n",
        "for folder in folders:\n",
        "    if not os.path.exists(folder):\n",
        "        continue\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().endswith(\".dav\"):\n",
        "            inpath = os.path.join(folder,f)\n",
        "            outpath = os.path.join(folder, os.path.splitext(f)[0] + \".mp4\")\n",
        "            if os.path.exists(outpath):\n",
        "                print(\"exists\", outpath); continue\n",
        "            cmd = [\"ffmpeg\",\"-i\", inpath, \"-c:v\", \"libx264\", \"-preset\", \"fast\", \"-crf\", \"23\", outpath, \"-y\"]\n",
        "            print(\"Converting\", inpath, \"->\", outpath)\n",
        "            subprocess.run(cmd, check=True)\n",
        "print(\"Done\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTGNut65l9-9",
        "outputId": "4bc0f596-1604-47bb-e7b4-2dffdbd02b0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exists /content/cashlifting/cctv_CAM 5_main_20250524212350.mp4\n",
            "exists /content/cashlifting/cctv_CAM 5_main_20250524212319.mp4\n",
            "exists /content/cashlifting/cctv_CAM 5_main_20250524212558.mp4\n",
            "exists /content/cashlifting/cctv_CAM 5_main_20250524212334.mp4\n",
            "exists /content/cashlifting/cctv_CAM 5_main_20250524212746.mp4\n",
            "exists /content/cashlifting/cctv_CAM 5_main_20250524212730.mp4\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Optimized GPU Clip Extraction (First 3 min for NORMAL)\n",
        "# ============================\n",
        "\n",
        "!pip install ffmpeg-python decord imageio tqdm\n",
        "\n",
        "import os, uuid, shutil, tempfile\n",
        "from decord import VideoReader, cpu, gpu\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "import ffmpeg\n",
        "\n",
        "# ==== CONFIG ====\n",
        "CLIP_LEN = 5       # seconds\n",
        "STRIDE = 2         # seconds between clip starts\n",
        "FPS_TARGET = 15    # fps for output clips\n",
        "max_normal_clips = 500   # reduce for testing\n",
        "max_cash_clips = None    # None -> all\n",
        "MAX_NORMAL_DURATION = 180  # seconds (3 minutes)\n",
        "\n",
        "# Paths\n",
        "NORMAL_DIR = \"/content/NORAML \"\n",
        "CASHLIFT_DIR = \"/content/cashlifting\"\n",
        "OUTPUT_CLIPS_DIR = \"/content/clips\"\n",
        "\n",
        "# Output folders\n",
        "for split in [\"train\", \"val\"]:\n",
        "    for cls in [\"normal\", \"cashlifting\"]:\n",
        "        os.makedirs(os.path.join(OUTPUT_CLIPS_DIR, split, cls), exist_ok=True)\n",
        "\n",
        "# ============================\n",
        "# Save clip to disk with low RAM usage\n",
        "# ============================\n",
        "def save_clip_frames(frames, out_path, fps=FPS_TARGET):\n",
        "    tmp_img_dir = tempfile.mkdtemp()\n",
        "    for i, f in enumerate(frames):\n",
        "        imageio.imwrite(os.path.join(tmp_img_dir, f\"{i:06d}.jpg\"), f, quality=90)\n",
        "    (\n",
        "        ffmpeg\n",
        "        .input(os.path.join(tmp_img_dir, '%06d.jpg'), framerate=fps)\n",
        "        .output(out_path, vcodec='libx264', crf=23, pix_fmt='yuv420p')\n",
        "        .overwrite_output()\n",
        "        .run(quiet=True)\n",
        "    )\n",
        "    shutil.rmtree(tmp_img_dir)\n",
        "\n",
        "# ============================\n",
        "# Extract clips from one video\n",
        "# ============================\n",
        "def extract_clips_from_video(video_path, out_dir, clip_len=CLIP_LEN, stride=STRIDE, fps_target=FPS_TARGET, max_clips=None, max_duration=None):\n",
        "    try:\n",
        "        vr = VideoReader(video_path, ctx=gpu(0))  # Use GPU decoding\n",
        "    except:\n",
        "        vr = VideoReader(video_path, ctx=cpu(0))  # Fallback to CPU if GPU decoding not available\n",
        "\n",
        "    src_fps = float(vr.get_avg_fps())\n",
        "    total_frames = len(vr)\n",
        "    duration = total_frames / src_fps\n",
        "\n",
        "    # Limit duration if requested\n",
        "    if max_duration is not None:\n",
        "        duration = min(duration, max_duration)\n",
        "\n",
        "    starts = np.arange(0, max(0, duration - clip_len + 1e-3), stride)\n",
        "    saved = 0\n",
        "\n",
        "    for s in tqdm(starts, desc=os.path.basename(video_path)):\n",
        "        if max_clips is not None and saved >= max_clips:\n",
        "            break\n",
        "\n",
        "        t0, t1 = s, s + clip_len\n",
        "        times = np.linspace(t0, t1, int(round(clip_len * fps_target)), endpoint=False)\n",
        "        idxs = np.clip((times * src_fps).astype(int), 0, total_frames - 1)\n",
        "\n",
        "        frames = []\n",
        "        for i in idxs:\n",
        "            frames.append(vr[i].asnumpy()[:,:,::-1])  # BGR â†’ RGB\n",
        "\n",
        "        if len(frames) < 3:\n",
        "            continue\n",
        "\n",
        "        out_p = os.path.join(out_dir, f\"{os.path.splitext(os.path.basename(video_path))[0]}_{int(s)}_{uuid.uuid4().hex[:6]}.mp4\")\n",
        "        save_clip_frames(frames, out_p, fps=fps_target)\n",
        "        saved += 1\n",
        "\n",
        "    return saved\n",
        "\n",
        "# ============================\n",
        "# Process Videos\n",
        "# ============================\n",
        "normal_files = [os.path.join(NORMAL_DIR, f) for f in os.listdir(NORMAL_DIR) if f.lower().endswith((\".mp4\", \".avi\", \".mov\"))]\n",
        "cash_files = [os.path.join(CASHLIFT_DIR, f) for f in os.listdir(CASHLIFT_DIR) if f.lower().endswith((\".mp4\", \".avi\", \".mov\"))]\n",
        "\n",
        "# Normal videos (first 3 minutes only)\n",
        "normal_saved = 0\n",
        "for nf in normal_files:\n",
        "    remaining = None if max_normal_clips is None else max_normal_clips - normal_saved\n",
        "    if remaining is not None and remaining <= 0:\n",
        "        break\n",
        "    saved = extract_clips_from_video(\n",
        "        nf,\n",
        "        os.path.join(OUTPUT_CLIPS_DIR, \"train\", \"normal\"),\n",
        "        max_clips=remaining,\n",
        "        max_duration=MAX_NORMAL_DURATION\n",
        "    )\n",
        "    normal_saved += saved\n",
        "\n",
        "# Cashlifting videos (full length)\n",
        "cash_saved = 0\n",
        "for cf in cash_files:\n",
        "    saved = extract_clips_from_video(\n",
        "        cf,\n",
        "        os.path.join(OUTPUT_CLIPS_DIR, \"train\", \"cashlifting\"),\n",
        "        max_clips=max_cash_clips\n",
        "    )\n",
        "    cash_saved += saved\n",
        "\n",
        "print(\"âœ… Saved normal clips:\", normal_saved, \" | Saved cash clips:\", cash_saved)\n",
        "\n",
        "\n",
        "'''\n",
        "This Crashes at normal of 1 video then we will pause and save that to the drive\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jo5-WSemGLt",
        "outputId": "d0c176b8-d847-42c5-f72d-a335f7e923fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from decord) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio) (11.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "video13.mp4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [33:06<00:00, 22.58s/it]\n",
            "video1.mp4:   0%|          | 0/88 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1ï¸âƒ£ Set source and destination paths\n",
        "# 2ï¸âƒ£ Set source and destination paths\n",
        "src_folder = \"/content/clips/train/normal\"\n",
        "dst_folder = \"/content/drive/MyDrive/clips/train/normal\"\n",
        "\n",
        "# 3ï¸âƒ£ Create destination folder if not exists\n",
        "os.makedirs(dst_folder, exist_ok=True)\n",
        "\n",
        "# 4ï¸âƒ£ Copy files\n",
        "shutil.copytree(src_folder, dst_folder, dirs_exist_ok=True)\n",
        "\n",
        "print(f\"âœ… All clips saved to: {dst_folder}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Euo2_HjEm_ww",
        "outputId": "928d796c-0191-4b10-a1a1-0665b514d320"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All clips saved to: /content/drive/MyDrive/clips/train/normal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Paths\n",
        "normal_dir = \"/content/NORAML \"\n",
        "cashlifting_dir = \"/content/cashlifting\"\n",
        "output_dir = \"/content/clips\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Parameters\n",
        "clip_len = 5  # seconds per clip\n",
        "fps_target = 15\n",
        "stride = 5    # seconds between clips\n",
        "\n",
        "def extract_clips(video_path, out_dir, clip_len, stride, fps_target):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"âŒ Failed to open {video_path}\")\n",
        "        return\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or fps_target\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = total_frames / fps\n",
        "    frame_step = int(fps * stride)\n",
        "    clip_frame_len = int(fps * clip_len)\n",
        "\n",
        "    vid_name = Path(video_path).stem\n",
        "    frame_idx = 0\n",
        "    clip_idx = 0\n",
        "\n",
        "    while frame_idx + clip_frame_len < total_frames:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "        frames = []\n",
        "        for _ in range(clip_frame_len):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            frames.append(frame)\n",
        "\n",
        "        if len(frames) == clip_frame_len:\n",
        "            out_path = os.path.join(out_dir, f\"{vid_name}_clip{clip_idx}.mp4\")\n",
        "            out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps_target, (224, 224))\n",
        "            for f in frames:\n",
        "                out.write(f)\n",
        "            out.release()\n",
        "\n",
        "        clip_idx += 1\n",
        "        frame_idx += frame_step\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"âœ… Processed {video_path} into {clip_idx} clips\")\n",
        "\n",
        "# Process all videos\n",
        "for folder, label in [(normal_dir, \"normal\"), (cashlifting_dir, \"cashlifting\")]:\n",
        "    label_dir = os.path.join(output_dir, label)\n",
        "    os.makedirs(label_dir, exist_ok=True)\n",
        "    for vid in os.listdir(folder):\n",
        "        vid_path = os.path.join(folder, vid)\n",
        "        extract_clips(vid_path, label_dir, clip_len, stride, fps_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXPcsygszqCK",
        "outputId": "ad59c3a6-0c5f-4fb4-80e4-4748681a9f33"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Processed /content/NORAML /video13.mp4 into 719 clips\n",
            "âœ… Processed /content/NORAML /video1.mp4 into 719 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212350.dav into 1 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212319.dav into 1 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212350.mp4 into 1 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212746.mp4 into 1 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212558.dav into 1 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212334.dav into 2 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212334.mp4 into 2 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212730.mp4 into 2 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212558.mp4 into 2 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212319.mp4 into 2 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212746.dav into 1 clips\n",
            "âœ… Processed /content/cashlifting/cctv_CAM 5_main_20250524212730.dav into 1 clips\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Processing the videos and clips"
      ],
      "metadata": {
        "id": "5vwAUsn04iyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/Priyanka_Project/cashlifting.zip -d /content"
      ],
      "metadata": {
        "id": "-FKDQPB49Hj-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ffmpeg\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/cashlifting\"\n",
        "output_folder = \"/content/cashlifting_mp4\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Convert all .dav files to .mp4\n",
        "for file in os.listdir(input_folder):\n",
        "    if file.lower().endswith(\".dav\"):\n",
        "        input_path = os.path.join(input_folder, file)\n",
        "        output_path = os.path.join(output_folder, os.path.splitext(file)[0] + \".mp4\")\n",
        "        print(f\"Converting {file} â†’ {os.path.basename(output_path)}\")\n",
        "        subprocess.run([\"ffmpeg\", \"-i\", input_path, \"-c:v\", \"libx264\", \"-preset\", \"fast\", \"-crf\", \"22\", \"-c:a\", \"aac\", output_path])\n",
        "\n",
        "print(\"âœ… All .dav files converted to .mp4!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8ZHrFjg-rnv",
        "outputId": "8645acd1-a22f-4964-c4ed-ddc825bd8305"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Converting cctv_CAM 5_main_20250524212350.dav â†’ cctv_CAM 5_main_20250524212350.mp4\n",
            "Converting cctv_CAM 5_main_20250524212319.dav â†’ cctv_CAM 5_main_20250524212319.mp4\n",
            "Converting cctv_CAM 5_main_20250524212558.dav â†’ cctv_CAM 5_main_20250524212558.mp4\n",
            "Converting cctv_CAM 5_main_20250524212334.dav â†’ cctv_CAM 5_main_20250524212334.mp4\n",
            "Converting cctv_CAM 5_main_20250524212746.dav â†’ cctv_CAM 5_main_20250524212746.mp4\n",
            "Converting cctv_CAM 5_main_20250524212730.dav â†’ cctv_CAM 5_main_20250524212730.mp4\n",
            "âœ… All .dav files converted to .mp4!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "import random\n",
        "\n",
        "# Paths\n",
        "normal_path = \"/content/drive/MyDrive/clips/train/normal\"\n",
        "cashlifting_path = \"/content/cashlifting_mp4\"\n",
        "TARGET_SIZE = (128, 128)\n",
        "SAMPLES_PER_CLASS = 21  # fixed number per class\n",
        "\n",
        "# Function to load frames from videos\n",
        "def load_frames_from_folder(folder, label, max_samples):\n",
        "    frames, labels = [], []\n",
        "    files = [f for f in os.listdir(folder) if f.lower().endswith(\".mp4\")]\n",
        "    random.shuffle(files)  # randomize selection\n",
        "    files = files[:max_samples]  # pick fixed number\n",
        "    for file in files:\n",
        "        cap = cv2.VideoCapture(os.path.join(folder, file))\n",
        "        ret, frame = cap.read()\n",
        "        cap.release()\n",
        "        if ret:\n",
        "            frame = cv2.resize(frame, TARGET_SIZE)\n",
        "            frames.append(frame)\n",
        "            labels.append(label)\n",
        "    return frames, labels\n",
        "\n",
        "# Load dataset (balanced)\n",
        "X_normal, y_normal = load_frames_from_folder(normal_path, 0, SAMPLES_PER_CLASS)\n",
        "X_cash, y_cash = load_frames_from_folder(cashlifting_path, 1, SAMPLES_PER_CLASS)\n",
        "\n",
        "# Combine and shuffle\n",
        "X = np.array(X_normal + X_cash, dtype=\"float32\")\n",
        "y = np.array(y_normal + y_cash)\n",
        "indices = np.arange(len(X))\n",
        "np.random.shuffle(indices)\n",
        "X = X[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Preprocess\n",
        "X = preprocess_input(X)\n",
        "y = to_categorical(y, num_classes=2)\n",
        "\n",
        "print(f\"ğŸ“Š Total dataset size: {len(X)} samples ({SAMPLES_PER_CLASS} per class)\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"âœ… Training set: {len(X_train)} samples\")\n",
        "print(f\"âœ… Test set: {len(X_test)} samples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I6aa2UZ7bCb",
        "outputId": "6f2bee42-c661-4009-9edd-588fe113c195"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Total dataset size: 27 samples (21 per class)\n",
            "âœ… Training set: 21 samples\n",
            "âœ… Test set: 6 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Check GPU\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"âš ï¸ WARNING: No GPU found. Training will be slow.\")\n",
        "\n",
        "# Build model\n",
        "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.3),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(1e-4), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"ğŸš€ Starting training...\")\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=16)\n",
        "\n",
        "# Save model\n",
        "model.save(\"/content/cashlifting_classifier.h5\")\n",
        "print(\"ğŸ’¾ Model saved as /content/cashlifting_classifier.h5\")\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"âœ… Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Predictions\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"\\nğŸ“Š Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"normal\", \"cashlifting\"]))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"normal\", \"cashlifting\"], yticklabels=[\"normal\", \"cashlifting\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "HjRpav-wBaKb",
        "outputId": "e67ac526-e42f-4f36-9cac-b77b37ec52f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "ğŸš€ Starting training...\n",
            "Epoch 1/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9s/step - accuracy: 0.3264 - loss: 1.1898 - val_accuracy: 0.1667 - val_loss: 1.3404\n",
            "Epoch 2/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.3790 - loss: 1.2544 - val_accuracy: 0.1667 - val_loss: 1.2370\n",
            "Epoch 3/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5575 - loss: 0.8932 - val_accuracy: 0.1667 - val_loss: 1.1425\n",
            "Epoch 4/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.3681 - loss: 1.0868 - val_accuracy: 0.1667 - val_loss: 1.0591\n",
            "Epoch 5/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4107 - loss: 1.0963 - val_accuracy: 0.1667 - val_loss: 0.9866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ Model saved as /content/cashlifting_classifier.h5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1667 - loss: 0.9866\n",
            "âœ… Test Accuracy: 16.67%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\n",
            "ğŸ“Š Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.50      0.20      0.29         5\n",
            " cashlifting       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.17         6\n",
            "   macro avg       0.25      0.10      0.14         6\n",
            "weighted avg       0.42      0.17      0.24         6\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the code"
      ],
      "metadata": {
        "id": "P9mFWIQVAbVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "#  TEST ON A SINGLE VIDEO\n",
        "# =========================\n",
        "\n",
        "def predict_single_video(video_path, model, target_size=(128, 128)):\n",
        "    import cv2\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"File not found: {video_path}\")\n",
        "        return\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "\n",
        "    if not ret:\n",
        "        print(\" Could not read frame from video.\")\n",
        "        return\n",
        "\n",
        "    # Preprocess\n",
        "    frame = cv2.resize(frame, target_size)\n",
        "    frame = np.expand_dims(frame, axis=0).astype(\"float32\")\n",
        "    frame = preprocess_input(frame)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(frame)\n",
        "    class_idx = np.argmax(pred, axis=1)[0]\n",
        "    class_names = [\"normal\", \"cashlifting\"]\n",
        "    confidence = pred[0][class_idx] * 100\n",
        "\n",
        "    print(f\" Prediction: {class_names[class_idx]} ({confidence:.2f}% confidence)\")\n",
        "\n",
        "# Example usage:\n",
        "test_video_path = \"/content/cashlifting_mp4/cctv_CAM 5_main_20250524212350.mp4\"\n",
        "predict_single_video(test_video_path, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlL6DI_j808d",
        "outputId": "390eade3-6854-4d6f-98d9-05a1406116e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
            "ğŸ¯ Prediction: cashlifting (75.98% confidence)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# ğŸ“Œ TEST ON A SINGLE VIDEO\n",
        "# =========================\n",
        "\n",
        "def predict_single_video(video_path, model, target_size=(128, 128)):\n",
        "    import cv2\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"âŒ File not found: {video_path}\")\n",
        "        return\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "\n",
        "    if not ret:\n",
        "        print(\"âŒ Could not read frame from video.\")\n",
        "        return\n",
        "\n",
        "    # Preprocess\n",
        "    frame = cv2.resize(frame, target_size)\n",
        "    frame = np.expand_dims(frame, axis=0).astype(\"float32\")\n",
        "    frame = preprocess_input(frame)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(frame)\n",
        "    class_idx = np.argmax(pred, axis=1)[0]\n",
        "    class_names = [\"normal\", \"cashlifting\"]\n",
        "    confidence = pred[0][class_idx] * 100\n",
        "\n",
        "    print(f\"ğŸ¯ Prediction: {class_names[class_idx]} ({confidence:.2f}% confidence)\")\n",
        "\n",
        "# Example usage:\n",
        "test_video_path = \"/content/cashlifting_mp4/cctv_CAM 5_main_20250524212319.mp4\"\n",
        "predict_single_video(test_video_path, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCPecZqjAWCV",
        "outputId": "e47f76ec-f917-4e4d-d8d6-054d3f1560ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "ğŸ¯ Prediction: normal (81.67% confidence)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zyfaGm75Cw7i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}